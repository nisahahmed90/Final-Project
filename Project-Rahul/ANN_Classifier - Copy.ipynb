{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Dependancies\n",
    "import pandas as pd\n",
    "from path import Path\n",
    "import sklearn as skl\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>admission_type_id</th>\n",
       "      <th>discharge_disposition_id</th>\n",
       "      <th>admission_source_id</th>\n",
       "      <th>time_in_hospital</th>\n",
       "      <th>num_lab_procedures</th>\n",
       "      <th>num_procedures</th>\n",
       "      <th>...</th>\n",
       "      <th>metformin</th>\n",
       "      <th>glimepiride</th>\n",
       "      <th>glipizide</th>\n",
       "      <th>glyburide</th>\n",
       "      <th>pioglitazone</th>\n",
       "      <th>rosiglitazone</th>\n",
       "      <th>insulin</th>\n",
       "      <th>change</th>\n",
       "      <th>diabetesMed</th>\n",
       "      <th>readmitted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Female</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Female</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>&gt;30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>AfricanAmerican</td>\n",
       "      <td>Female</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Male</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Male</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id             race  gender  age  admission_type_id  \\\n",
       "0   1        Caucasian  Female    5                  6   \n",
       "1   2        Caucasian  Female   15                  1   \n",
       "2   3  AfricanAmerican  Female   25                  1   \n",
       "3   4        Caucasian    Male   35                  1   \n",
       "4   5        Caucasian    Male   45                  1   \n",
       "\n",
       "   discharge_disposition_id  admission_source_id  time_in_hospital  \\\n",
       "0                        25                    1                 1   \n",
       "1                         1                    7                 3   \n",
       "2                         1                    7                 2   \n",
       "3                         1                    7                 2   \n",
       "4                         1                    7                 1   \n",
       "\n",
       "   num_lab_procedures  num_procedures  ...  metformin  glimepiride  glipizide  \\\n",
       "0                  41               0  ...          0            0          0   \n",
       "1                  59               0  ...          0            0          0   \n",
       "2                  11               5  ...          0            0          2   \n",
       "3                  44               1  ...          0            0          0   \n",
       "4                  51               0  ...          0            0          2   \n",
       "\n",
       "   glyburide  pioglitazone  rosiglitazone  insulin  change  diabetesMed  \\\n",
       "0          0             0              0        0       0            0   \n",
       "1          0             0              0        3       1            1   \n",
       "2          0             0              0        0       0            1   \n",
       "3          0             0              0        3       1            1   \n",
       "4          0             0              0        2       1            1   \n",
       "\n",
       "   readmitted  \n",
       "0          NO  \n",
       "1         >30  \n",
       "2          NO  \n",
       "3          NO  \n",
       "4          NO  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "file_path = \"../diabetes-filtered.csv\"\n",
    "df2 = pd.read_csv(file_path)\n",
    "df2.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encode Reamditted Column\n",
    "\n",
    "df2['readmitted']=df2['readmitted'].replace('NO', 0)\n",
    "df2['readmitted']=df2['readmitted'].replace('>30', 1)\n",
    "df2['readmitted']=df2['readmitted'].replace('<30', 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Rahul\\anaconda3\\envs\\mlenv\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "c:\\Users\\Rahul\\anaconda3\\envs\\mlenv\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#Encoding the Data\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder(sparse = False)\n",
    "\n",
    "#Encode Column Race\n",
    "encode_df = pd.DataFrame(enc.fit_transform(df2.race.values.reshape(-1,1)))\n",
    "\n",
    "#Rename encoded columns\n",
    "encode_df.columns = enc.get_feature_names(['race'])\n",
    "\n",
    "\n",
    "# Merge Dataframes\n",
    "df2 = df2.merge(encode_df,left_index=True,right_index=True)\n",
    "\n",
    "#Encoding the Data\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder(sparse = False)\n",
    "\n",
    "#Encode Column Race\n",
    "encode_df2 = pd.DataFrame(enc.fit_transform(df2.gender.values.reshape(-1,1)))\n",
    "\n",
    "#Rename encoded columns\n",
    "encode_df2.columns = enc.get_feature_names(['gender'])\n",
    "\n",
    "# Merge Dataframes\n",
    "df2 = df2.merge(encode_df2,left_index=True,right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>admission_type_id</th>\n",
       "      <th>discharge_disposition_id</th>\n",
       "      <th>admission_source_id</th>\n",
       "      <th>time_in_hospital</th>\n",
       "      <th>num_lab_procedures</th>\n",
       "      <th>num_procedures</th>\n",
       "      <th>num_medications</th>\n",
       "      <th>number_outpatient</th>\n",
       "      <th>number_emergency</th>\n",
       "      <th>...</th>\n",
       "      <th>change</th>\n",
       "      <th>diabetesMed</th>\n",
       "      <th>race_AfricanAmerican</th>\n",
       "      <th>race_Asian</th>\n",
       "      <th>race_Caucasian</th>\n",
       "      <th>race_Hispanic</th>\n",
       "      <th>race_Other</th>\n",
       "      <th>gender_Female</th>\n",
       "      <th>gender_Male</th>\n",
       "      <th>gender_Unknown/Invalid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71513</th>\n",
       "      <td>75</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71514</th>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>73</td>\n",
       "      <td>6</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71515</th>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>46</td>\n",
       "      <td>6</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71516</th>\n",
       "      <td>85</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71517</th>\n",
       "      <td>75</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>71518 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age  admission_type_id  discharge_disposition_id  admission_source_id  \\\n",
       "0        5                  6                        25                    1   \n",
       "1       15                  1                         1                    7   \n",
       "2       25                  1                         1                    7   \n",
       "3       35                  1                         1                    7   \n",
       "4       45                  1                         1                    7   \n",
       "...    ...                ...                       ...                  ...   \n",
       "71513   75                  1                         1                    7   \n",
       "71514   45                  1                         1                    7   \n",
       "71515   65                  1                         1                    7   \n",
       "71516   85                  1                         1                    7   \n",
       "71517   75                  1                         1                    7   \n",
       "\n",
       "       time_in_hospital  num_lab_procedures  num_procedures  num_medications  \\\n",
       "0                     1                  41               0                1   \n",
       "1                     3                  59               0               18   \n",
       "2                     2                  11               5               13   \n",
       "3                     2                  44               1               16   \n",
       "4                     1                  51               0                8   \n",
       "...                 ...                 ...             ...              ...   \n",
       "71513                 9                  50               2               33   \n",
       "71514                14                  73               6               26   \n",
       "71515                 2                  46               6               17   \n",
       "71516                 5                  76               1               22   \n",
       "71517                 6                  13               3                3   \n",
       "\n",
       "       number_outpatient  number_emergency  ...  change  diabetesMed  \\\n",
       "0                      0                 0  ...       0            0   \n",
       "1                      0                 0  ...       1            1   \n",
       "2                      2                 0  ...       0            1   \n",
       "3                      0                 0  ...       1            1   \n",
       "4                      0                 0  ...       1            1   \n",
       "...                  ...               ...  ...     ...          ...   \n",
       "71513                  0                 0  ...       1            1   \n",
       "71514                  0                 1  ...       1            1   \n",
       "71515                  1                 1  ...       0            1   \n",
       "71516                  0                 1  ...       1            1   \n",
       "71517                  0                 0  ...       0            0   \n",
       "\n",
       "       race_AfricanAmerican  race_Asian  race_Caucasian  race_Hispanic  \\\n",
       "0                       0.0         0.0             1.0            0.0   \n",
       "1                       0.0         0.0             1.0            0.0   \n",
       "2                       1.0         0.0             0.0            0.0   \n",
       "3                       0.0         0.0             1.0            0.0   \n",
       "4                       0.0         0.0             1.0            0.0   \n",
       "...                     ...         ...             ...            ...   \n",
       "71513                   0.0         0.0             1.0            0.0   \n",
       "71514                   0.0         0.0             0.0            0.0   \n",
       "71515                   0.0         0.0             0.0            0.0   \n",
       "71516                   0.0         0.0             1.0            0.0   \n",
       "71517                   0.0         0.0             1.0            0.0   \n",
       "\n",
       "       race_Other  gender_Female  gender_Male  gender_Unknown/Invalid  \n",
       "0             0.0            1.0          0.0                     0.0  \n",
       "1             0.0            1.0          0.0                     0.0  \n",
       "2             0.0            1.0          0.0                     0.0  \n",
       "3             0.0            0.0          1.0                     0.0  \n",
       "4             0.0            0.0          1.0                     0.0  \n",
       "...           ...            ...          ...                     ...  \n",
       "71513         0.0            1.0          0.0                     0.0  \n",
       "71514         1.0            1.0          0.0                     0.0  \n",
       "71515         1.0            1.0          0.0                     0.0  \n",
       "71516         0.0            1.0          0.0                     0.0  \n",
       "71517         0.0            0.0          1.0                     0.0  \n",
       "\n",
       "[71518 rows x 34 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Classify X and y Data\n",
    "\n",
    "y = df2['readmitted']\n",
    "X = df2.drop(columns = ['race','gender','id','readmitted'])\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create testing and training set\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y, train_size = 0.7, random_state = 6, stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create scaler instance\n",
    "X_scaler = skl.preprocessing.StandardScaler()\n",
    "\n",
    "# Fit the scaler\n",
    "X_scaler.fit(X_train)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Keras Sequential model\n",
    "nn_model = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_3 (Dense)             (None, 36)                1260      \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 15)                555       \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 16        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,831\n",
      "Trainable params: 1,831\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Add our first Dense layer, including the input layer\n",
    "inputs = len(X_train_scaled[0])\n",
    "\n",
    "nodes_first_layer = 36\n",
    "nodes_second_layer = 15\n",
    "\n",
    "# Input Layer\n",
    "nn_model.add(tf.keras.layers.Dense(units=nodes_first_layer, activation=\"tanh\", input_dim=inputs))\n",
    "\n",
    "# Second Layer\n",
    "nn_model.add(tf.keras.layers.Dense(units=nodes_second_layer, activation=\"tanh\"))\n",
    "\n",
    "# Output layer\n",
    "nn_model.add(tf.keras.layers.Dense(units = 1, activation=\"sigmoid\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "nn_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "1565/1565 [==============================] - 1s 666us/step - loss: 0.6546 - accuracy: 0.6208\n",
      "Epoch 2/200\n",
      "1565/1565 [==============================] - 1s 669us/step - loss: 0.6471 - accuracy: 0.6275\n",
      "Epoch 3/200\n",
      "1565/1565 [==============================] - 1s 657us/step - loss: 0.6439 - accuracy: 0.6313\n",
      "Epoch 4/200\n",
      "1565/1565 [==============================] - 1s 657us/step - loss: 0.6412 - accuracy: 0.6331\n",
      "Epoch 5/200\n",
      "1565/1565 [==============================] - 1s 654us/step - loss: 0.6393 - accuracy: 0.6351\n",
      "Epoch 6/200\n",
      "1565/1565 [==============================] - 1s 645us/step - loss: 0.6378 - accuracy: 0.6371\n",
      "Epoch 7/200\n",
      "1565/1565 [==============================] - 1s 645us/step - loss: 0.6359 - accuracy: 0.6382\n",
      "Epoch 8/200\n",
      "1565/1565 [==============================] - 1s 662us/step - loss: 0.6350 - accuracy: 0.6383\n",
      "Epoch 9/200\n",
      "1565/1565 [==============================] - 1s 659us/step - loss: 0.6336 - accuracy: 0.6418\n",
      "Epoch 10/200\n",
      "1565/1565 [==============================] - 1s 682us/step - loss: 0.6327 - accuracy: 0.6400\n",
      "Epoch 11/200\n",
      "1565/1565 [==============================] - 1s 670us/step - loss: 0.6317 - accuracy: 0.6429\n",
      "Epoch 12/200\n",
      "1565/1565 [==============================] - 1s 702us/step - loss: 0.6301 - accuracy: 0.6438\n",
      "Epoch 13/200\n",
      "1565/1565 [==============================] - 1s 703us/step - loss: 0.6294 - accuracy: 0.6451\n",
      "Epoch 14/200\n",
      "1565/1565 [==============================] - 1s 660us/step - loss: 0.6282 - accuracy: 0.6463\n",
      "Epoch 15/200\n",
      "1565/1565 [==============================] - 1s 657us/step - loss: 0.6274 - accuracy: 0.6462\n",
      "Epoch 16/200\n",
      "1565/1565 [==============================] - 1s 642us/step - loss: 0.6265 - accuracy: 0.6480\n",
      "Epoch 17/200\n",
      "1565/1565 [==============================] - 1s 638us/step - loss: 0.6257 - accuracy: 0.6476\n",
      "Epoch 18/200\n",
      "1565/1565 [==============================] - 1s 642us/step - loss: 0.6250 - accuracy: 0.6484\n",
      "Epoch 19/200\n",
      "1565/1565 [==============================] - 1s 635us/step - loss: 0.6243 - accuracy: 0.6485\n",
      "Epoch 20/200\n",
      "1565/1565 [==============================] - 1s 642us/step - loss: 0.6235 - accuracy: 0.6507\n",
      "Epoch 21/200\n",
      "1565/1565 [==============================] - 1s 641us/step - loss: 0.6227 - accuracy: 0.6504\n",
      "Epoch 22/200\n",
      "1565/1565 [==============================] - 1s 641us/step - loss: 0.6222 - accuracy: 0.6512\n",
      "Epoch 23/200\n",
      "1565/1565 [==============================] - 1s 641us/step - loss: 0.6214 - accuracy: 0.6510\n",
      "Epoch 24/200\n",
      "1565/1565 [==============================] - 1s 640us/step - loss: 0.6207 - accuracy: 0.6524\n",
      "Epoch 25/200\n",
      "1565/1565 [==============================] - 1s 654us/step - loss: 0.6198 - accuracy: 0.6547\n",
      "Epoch 26/200\n",
      "1565/1565 [==============================] - 1s 639us/step - loss: 0.6195 - accuracy: 0.6550\n",
      "Epoch 27/200\n",
      "1565/1565 [==============================] - 1s 644us/step - loss: 0.6188 - accuracy: 0.6542\n",
      "Epoch 28/200\n",
      "1565/1565 [==============================] - 1s 647us/step - loss: 0.6179 - accuracy: 0.6569\n",
      "Epoch 29/200\n",
      "1565/1565 [==============================] - 1s 648us/step - loss: 0.6174 - accuracy: 0.6559\n",
      "Epoch 30/200\n",
      "1565/1565 [==============================] - 1s 638us/step - loss: 0.6168 - accuracy: 0.6577\n",
      "Epoch 31/200\n",
      "1565/1565 [==============================] - 1s 640us/step - loss: 0.6159 - accuracy: 0.6573\n",
      "Epoch 32/200\n",
      "1565/1565 [==============================] - 1s 635us/step - loss: 0.6153 - accuracy: 0.6599\n",
      "Epoch 33/200\n",
      "1565/1565 [==============================] - 1s 642us/step - loss: 0.6146 - accuracy: 0.6599\n",
      "Epoch 34/200\n",
      "1565/1565 [==============================] - 1s 646us/step - loss: 0.6144 - accuracy: 0.6604\n",
      "Epoch 35/200\n",
      "1565/1565 [==============================] - 1s 639us/step - loss: 0.6135 - accuracy: 0.6629\n",
      "Epoch 36/200\n",
      "1565/1565 [==============================] - 1s 643us/step - loss: 0.6132 - accuracy: 0.6635\n",
      "Epoch 37/200\n",
      "1565/1565 [==============================] - 1s 660us/step - loss: 0.6127 - accuracy: 0.6630\n",
      "Epoch 38/200\n",
      "1565/1565 [==============================] - 1s 657us/step - loss: 0.6123 - accuracy: 0.6631\n",
      "Epoch 39/200\n",
      "1565/1565 [==============================] - 1s 658us/step - loss: 0.6116 - accuracy: 0.6625\n",
      "Epoch 40/200\n",
      "1565/1565 [==============================] - 1s 659us/step - loss: 0.6111 - accuracy: 0.6635\n",
      "Epoch 41/200\n",
      "1565/1565 [==============================] - 1s 658us/step - loss: 0.6108 - accuracy: 0.6646\n",
      "Epoch 42/200\n",
      "1565/1565 [==============================] - 1s 658us/step - loss: 0.6106 - accuracy: 0.6651\n",
      "Epoch 43/200\n",
      "1565/1565 [==============================] - 1s 657us/step - loss: 0.6100 - accuracy: 0.6650\n",
      "Epoch 44/200\n",
      "1565/1565 [==============================] - 1s 653us/step - loss: 0.6096 - accuracy: 0.6648\n",
      "Epoch 45/200\n",
      "1565/1565 [==============================] - 1s 659us/step - loss: 0.6094 - accuracy: 0.6644\n",
      "Epoch 46/200\n",
      "1565/1565 [==============================] - 1s 659us/step - loss: 0.6088 - accuracy: 0.6663\n",
      "Epoch 47/200\n",
      "1565/1565 [==============================] - 1s 660us/step - loss: 0.6088 - accuracy: 0.6656\n",
      "Epoch 48/200\n",
      "1565/1565 [==============================] - 1s 652us/step - loss: 0.6085 - accuracy: 0.6672\n",
      "Epoch 49/200\n",
      "1565/1565 [==============================] - 1s 665us/step - loss: 0.6082 - accuracy: 0.6655\n",
      "Epoch 50/200\n",
      "1565/1565 [==============================] - 1s 658us/step - loss: 0.6078 - accuracy: 0.6678\n",
      "Epoch 51/200\n",
      "1565/1565 [==============================] - 1s 648us/step - loss: 0.6072 - accuracy: 0.6682\n",
      "Epoch 52/200\n",
      "1565/1565 [==============================] - 1s 649us/step - loss: 0.6070 - accuracy: 0.6660\n",
      "Epoch 53/200\n",
      "1565/1565 [==============================] - 1s 655us/step - loss: 0.6067 - accuracy: 0.6680\n",
      "Epoch 54/200\n",
      "1565/1565 [==============================] - 1s 659us/step - loss: 0.6061 - accuracy: 0.6672\n",
      "Epoch 55/200\n",
      "1565/1565 [==============================] - 1s 658us/step - loss: 0.6060 - accuracy: 0.6680\n",
      "Epoch 56/200\n",
      "1565/1565 [==============================] - 1s 659us/step - loss: 0.6058 - accuracy: 0.6672\n",
      "Epoch 57/200\n",
      "1565/1565 [==============================] - 1s 660us/step - loss: 0.6056 - accuracy: 0.6667\n",
      "Epoch 58/200\n",
      "1565/1565 [==============================] - 1s 653us/step - loss: 0.6051 - accuracy: 0.6689\n",
      "Epoch 59/200\n",
      "1565/1565 [==============================] - 1s 656us/step - loss: 0.6049 - accuracy: 0.6684\n",
      "Epoch 60/200\n",
      "1565/1565 [==============================] - 1s 658us/step - loss: 0.6046 - accuracy: 0.6688\n",
      "Epoch 61/200\n",
      "1565/1565 [==============================] - 1s 658us/step - loss: 0.6044 - accuracy: 0.6715\n",
      "Epoch 62/200\n",
      "1565/1565 [==============================] - 1s 669us/step - loss: 0.6042 - accuracy: 0.6687\n",
      "Epoch 63/200\n",
      "1565/1565 [==============================] - 1s 657us/step - loss: 0.6041 - accuracy: 0.6712\n",
      "Epoch 64/200\n",
      "1565/1565 [==============================] - 1s 661us/step - loss: 0.6035 - accuracy: 0.6693\n",
      "Epoch 65/200\n",
      "1565/1565 [==============================] - 1s 660us/step - loss: 0.6033 - accuracy: 0.6708\n",
      "Epoch 66/200\n",
      "1565/1565 [==============================] - 1s 642us/step - loss: 0.6032 - accuracy: 0.6703\n",
      "Epoch 67/200\n",
      "1565/1565 [==============================] - 1s 654us/step - loss: 0.6030 - accuracy: 0.6688\n",
      "Epoch 68/200\n",
      "1565/1565 [==============================] - 1s 660us/step - loss: 0.6026 - accuracy: 0.6714\n",
      "Epoch 69/200\n",
      "1565/1565 [==============================] - 1s 659us/step - loss: 0.6025 - accuracy: 0.6704\n",
      "Epoch 70/200\n",
      "1565/1565 [==============================] - 1s 653us/step - loss: 0.6023 - accuracy: 0.6702\n",
      "Epoch 71/200\n",
      "1565/1565 [==============================] - 1s 645us/step - loss: 0.6017 - accuracy: 0.6707\n",
      "Epoch 72/200\n",
      "1565/1565 [==============================] - 1s 642us/step - loss: 0.6015 - accuracy: 0.6719\n",
      "Epoch 73/200\n",
      "1565/1565 [==============================] - 1s 656us/step - loss: 0.6014 - accuracy: 0.6720\n",
      "Epoch 74/200\n",
      "1565/1565 [==============================] - 1s 664us/step - loss: 0.6012 - accuracy: 0.6729\n",
      "Epoch 75/200\n",
      "1565/1565 [==============================] - 1s 659us/step - loss: 0.6007 - accuracy: 0.6723\n",
      "Epoch 76/200\n",
      "1565/1565 [==============================] - 1s 652us/step - loss: 0.6007 - accuracy: 0.6714\n",
      "Epoch 77/200\n",
      "1565/1565 [==============================] - 1s 657us/step - loss: 0.6004 - accuracy: 0.6724\n",
      "Epoch 78/200\n",
      "1565/1565 [==============================] - 1s 656us/step - loss: 0.6003 - accuracy: 0.6718\n",
      "Epoch 79/200\n",
      "1565/1565 [==============================] - 1s 654us/step - loss: 0.5998 - accuracy: 0.6737\n",
      "Epoch 80/200\n",
      "1565/1565 [==============================] - 1s 658us/step - loss: 0.5999 - accuracy: 0.6727\n",
      "Epoch 81/200\n",
      "1565/1565 [==============================] - 1s 654us/step - loss: 0.5996 - accuracy: 0.6727\n",
      "Epoch 82/200\n",
      "1565/1565 [==============================] - 1s 656us/step - loss: 0.5993 - accuracy: 0.6733\n",
      "Epoch 83/200\n",
      "1565/1565 [==============================] - 1s 649us/step - loss: 0.5990 - accuracy: 0.6747\n",
      "Epoch 84/200\n",
      "1565/1565 [==============================] - 1s 661us/step - loss: 0.5989 - accuracy: 0.6741\n",
      "Epoch 85/200\n",
      "1565/1565 [==============================] - 1s 660us/step - loss: 0.5984 - accuracy: 0.6748\n",
      "Epoch 86/200\n",
      "1565/1565 [==============================] - 1s 652us/step - loss: 0.5985 - accuracy: 0.6754\n",
      "Epoch 87/200\n",
      "1565/1565 [==============================] - 1s 640us/step - loss: 0.5981 - accuracy: 0.6745\n",
      "Epoch 88/200\n",
      "1565/1565 [==============================] - 1s 643us/step - loss: 0.5979 - accuracy: 0.6753\n",
      "Epoch 89/200\n",
      "1565/1565 [==============================] - 1s 640us/step - loss: 0.5978 - accuracy: 0.6738\n",
      "Epoch 90/200\n",
      "1565/1565 [==============================] - 1s 643us/step - loss: 0.5977 - accuracy: 0.6748\n",
      "Epoch 91/200\n",
      "1565/1565 [==============================] - 1s 636us/step - loss: 0.5976 - accuracy: 0.6762\n",
      "Epoch 92/200\n",
      "1565/1565 [==============================] - 1s 635us/step - loss: 0.5975 - accuracy: 0.6748\n",
      "Epoch 93/200\n",
      "1565/1565 [==============================] - 1s 640us/step - loss: 0.5970 - accuracy: 0.6760\n",
      "Epoch 94/200\n",
      "1565/1565 [==============================] - 1s 639us/step - loss: 0.5972 - accuracy: 0.6768\n",
      "Epoch 95/200\n",
      "1565/1565 [==============================] - 1s 641us/step - loss: 0.5969 - accuracy: 0.6741\n",
      "Epoch 96/200\n",
      "1565/1565 [==============================] - 1s 637us/step - loss: 0.5967 - accuracy: 0.6750\n",
      "Epoch 97/200\n",
      "1565/1565 [==============================] - 1s 642us/step - loss: 0.5962 - accuracy: 0.6764\n",
      "Epoch 98/200\n",
      "1565/1565 [==============================] - 1s 652us/step - loss: 0.5964 - accuracy: 0.6754\n",
      "Epoch 99/200\n",
      "1565/1565 [==============================] - 1s 639us/step - loss: 0.5961 - accuracy: 0.6772\n",
      "Epoch 100/200\n",
      "1565/1565 [==============================] - 1s 641us/step - loss: 0.5958 - accuracy: 0.6766\n",
      "Epoch 101/200\n",
      "1565/1565 [==============================] - 1s 643us/step - loss: 0.5957 - accuracy: 0.6757\n",
      "Epoch 102/200\n",
      "1565/1565 [==============================] - 1s 646us/step - loss: 0.5957 - accuracy: 0.6760\n",
      "Epoch 103/200\n",
      "1565/1565 [==============================] - 1s 643us/step - loss: 0.5953 - accuracy: 0.6770\n",
      "Epoch 104/200\n",
      "1565/1565 [==============================] - 1s 640us/step - loss: 0.5955 - accuracy: 0.6774\n",
      "Epoch 105/200\n",
      "1565/1565 [==============================] - 1s 638us/step - loss: 0.5950 - accuracy: 0.6771\n",
      "Epoch 106/200\n",
      "1565/1565 [==============================] - 1s 641us/step - loss: 0.5948 - accuracy: 0.6762\n",
      "Epoch 107/200\n",
      "1565/1565 [==============================] - 1s 638us/step - loss: 0.5948 - accuracy: 0.6773\n",
      "Epoch 108/200\n",
      "1565/1565 [==============================] - 1s 641us/step - loss: 0.5948 - accuracy: 0.6778\n",
      "Epoch 109/200\n",
      "1565/1565 [==============================] - 1s 640us/step - loss: 0.5944 - accuracy: 0.6767\n",
      "Epoch 110/200\n",
      "1565/1565 [==============================] - 1s 644us/step - loss: 0.5944 - accuracy: 0.6763\n",
      "Epoch 111/200\n",
      "1565/1565 [==============================] - 1s 651us/step - loss: 0.5943 - accuracy: 0.6764\n",
      "Epoch 112/200\n",
      "1565/1565 [==============================] - 1s 643us/step - loss: 0.5941 - accuracy: 0.6774\n",
      "Epoch 113/200\n",
      "1565/1565 [==============================] - 1s 641us/step - loss: 0.5941 - accuracy: 0.6771\n",
      "Epoch 114/200\n",
      "1565/1565 [==============================] - 1s 642us/step - loss: 0.5939 - accuracy: 0.6767\n",
      "Epoch 115/200\n",
      "1565/1565 [==============================] - 1s 642us/step - loss: 0.5939 - accuracy: 0.6782\n",
      "Epoch 116/200\n",
      "1565/1565 [==============================] - 1s 645us/step - loss: 0.5936 - accuracy: 0.6768\n",
      "Epoch 117/200\n",
      "1565/1565 [==============================] - 1s 641us/step - loss: 0.5935 - accuracy: 0.6780\n",
      "Epoch 118/200\n",
      "1565/1565 [==============================] - 1s 641us/step - loss: 0.5932 - accuracy: 0.6776\n",
      "Epoch 119/200\n",
      "1565/1565 [==============================] - 1s 645us/step - loss: 0.5931 - accuracy: 0.6779\n",
      "Epoch 120/200\n",
      "1565/1565 [==============================] - 1s 643us/step - loss: 0.5932 - accuracy: 0.6793\n",
      "Epoch 121/200\n",
      "1565/1565 [==============================] - 1s 658us/step - loss: 0.5930 - accuracy: 0.6788\n",
      "Epoch 122/200\n",
      "1565/1565 [==============================] - 1s 640us/step - loss: 0.5926 - accuracy: 0.6788\n",
      "Epoch 123/200\n",
      "1565/1565 [==============================] - 1s 657us/step - loss: 0.5927 - accuracy: 0.6791\n",
      "Epoch 124/200\n",
      "1565/1565 [==============================] - 1s 657us/step - loss: 0.5923 - accuracy: 0.6798\n",
      "Epoch 125/200\n",
      "1565/1565 [==============================] - 1s 655us/step - loss: 0.5924 - accuracy: 0.6789\n",
      "Epoch 126/200\n",
      "1565/1565 [==============================] - 1s 655us/step - loss: 0.5919 - accuracy: 0.6793\n",
      "Epoch 127/200\n",
      "1565/1565 [==============================] - 1s 652us/step - loss: 0.5920 - accuracy: 0.6790\n",
      "Epoch 128/200\n",
      "1565/1565 [==============================] - 1s 653us/step - loss: 0.5918 - accuracy: 0.6802\n",
      "Epoch 129/200\n",
      "1565/1565 [==============================] - 1s 656us/step - loss: 0.5919 - accuracy: 0.6790\n",
      "Epoch 130/200\n",
      "1565/1565 [==============================] - 1s 654us/step - loss: 0.5916 - accuracy: 0.6790\n",
      "Epoch 131/200\n",
      "1565/1565 [==============================] - 1s 641us/step - loss: 0.5915 - accuracy: 0.6781\n",
      "Epoch 132/200\n",
      "1565/1565 [==============================] - 1s 654us/step - loss: 0.5915 - accuracy: 0.6803\n",
      "Epoch 133/200\n",
      "1565/1565 [==============================] - 1s 657us/step - loss: 0.5913 - accuracy: 0.6812\n",
      "Epoch 134/200\n",
      "1565/1565 [==============================] - 1s 656us/step - loss: 0.5911 - accuracy: 0.6811\n",
      "Epoch 135/200\n",
      "1565/1565 [==============================] - 1s 656us/step - loss: 0.5911 - accuracy: 0.6808\n",
      "Epoch 136/200\n",
      "1565/1565 [==============================] - 1s 652us/step - loss: 0.5907 - accuracy: 0.6799\n",
      "Epoch 137/200\n",
      "1565/1565 [==============================] - 1s 641us/step - loss: 0.5907 - accuracy: 0.6791\n",
      "Epoch 138/200\n",
      "1565/1565 [==============================] - 1s 639us/step - loss: 0.5905 - accuracy: 0.6806\n",
      "Epoch 139/200\n",
      "1565/1565 [==============================] - 1s 639us/step - loss: 0.5907 - accuracy: 0.6813\n",
      "Epoch 140/200\n",
      "1565/1565 [==============================] - 1s 639us/step - loss: 0.5902 - accuracy: 0.6800\n",
      "Epoch 141/200\n",
      "1565/1565 [==============================] - 1s 641us/step - loss: 0.5902 - accuracy: 0.6801\n",
      "Epoch 142/200\n",
      "1565/1565 [==============================] - 1s 639us/step - loss: 0.5901 - accuracy: 0.6812\n",
      "Epoch 143/200\n",
      "1565/1565 [==============================] - 1s 637us/step - loss: 0.5901 - accuracy: 0.6801\n",
      "Epoch 144/200\n",
      "1565/1565 [==============================] - 1s 638us/step - loss: 0.5898 - accuracy: 0.6807\n",
      "Epoch 145/200\n",
      "1565/1565 [==============================] - 1s 637us/step - loss: 0.5896 - accuracy: 0.6803\n",
      "Epoch 146/200\n",
      "1565/1565 [==============================] - 1s 640us/step - loss: 0.5897 - accuracy: 0.6806\n",
      "Epoch 147/200\n",
      "1565/1565 [==============================] - 1s 637us/step - loss: 0.5896 - accuracy: 0.6817\n",
      "Epoch 148/200\n",
      "1565/1565 [==============================] - 1s 653us/step - loss: 0.5895 - accuracy: 0.6820\n",
      "Epoch 149/200\n",
      "1565/1565 [==============================] - 1s 640us/step - loss: 0.5893 - accuracy: 0.6834\n",
      "Epoch 150/200\n",
      "1565/1565 [==============================] - 1s 639us/step - loss: 0.5892 - accuracy: 0.6819\n",
      "Epoch 151/200\n",
      "1565/1565 [==============================] - 1s 636us/step - loss: 0.5891 - accuracy: 0.6820\n",
      "Epoch 152/200\n",
      "1565/1565 [==============================] - 1s 633us/step - loss: 0.5891 - accuracy: 0.6817\n",
      "Epoch 153/200\n",
      "1565/1565 [==============================] - 1s 637us/step - loss: 0.5888 - accuracy: 0.6808\n",
      "Epoch 154/200\n",
      "1565/1565 [==============================] - 1s 638us/step - loss: 0.5887 - accuracy: 0.6830\n",
      "Epoch 155/200\n",
      "1565/1565 [==============================] - 1s 637us/step - loss: 0.5887 - accuracy: 0.6824\n",
      "Epoch 156/200\n",
      "1565/1565 [==============================] - 1s 642us/step - loss: 0.5885 - accuracy: 0.6830\n",
      "Epoch 157/200\n",
      "1565/1565 [==============================] - 1s 637us/step - loss: 0.5885 - accuracy: 0.6819\n",
      "Epoch 158/200\n",
      "1565/1565 [==============================] - 1s 636us/step - loss: 0.5882 - accuracy: 0.6830\n",
      "Epoch 159/200\n",
      "1565/1565 [==============================] - 1s 635us/step - loss: 0.5884 - accuracy: 0.6822\n",
      "Epoch 160/200\n",
      "1565/1565 [==============================] - 1s 637us/step - loss: 0.5882 - accuracy: 0.6837\n",
      "Epoch 161/200\n",
      "1565/1565 [==============================] - 1s 651us/step - loss: 0.5880 - accuracy: 0.6819\n",
      "Epoch 162/200\n",
      "1565/1565 [==============================] - 1s 639us/step - loss: 0.5879 - accuracy: 0.6823\n",
      "Epoch 163/200\n",
      "1565/1565 [==============================] - 1s 637us/step - loss: 0.5880 - accuracy: 0.6836\n",
      "Epoch 164/200\n",
      "1565/1565 [==============================] - 1s 637us/step - loss: 0.5876 - accuracy: 0.6831\n",
      "Epoch 165/200\n",
      "1565/1565 [==============================] - 1s 639us/step - loss: 0.5877 - accuracy: 0.6828\n",
      "Epoch 166/200\n",
      "1565/1565 [==============================] - 1s 637us/step - loss: 0.5875 - accuracy: 0.6844\n",
      "Epoch 167/200\n",
      "1565/1565 [==============================] - 1s 636us/step - loss: 0.5873 - accuracy: 0.6835\n",
      "Epoch 168/200\n",
      "1565/1565 [==============================] - 1s 634us/step - loss: 0.5872 - accuracy: 0.6842\n",
      "Epoch 169/200\n",
      "1565/1565 [==============================] - 1s 637us/step - loss: 0.5872 - accuracy: 0.6833\n",
      "Epoch 170/200\n",
      "1565/1565 [==============================] - 1s 637us/step - loss: 0.5871 - accuracy: 0.6840\n",
      "Epoch 171/200\n",
      "1565/1565 [==============================] - 1s 639us/step - loss: 0.5870 - accuracy: 0.6849\n",
      "Epoch 172/200\n",
      "1565/1565 [==============================] - 1s 634us/step - loss: 0.5870 - accuracy: 0.6833\n",
      "Epoch 173/200\n",
      "1565/1565 [==============================] - 1s 645us/step - loss: 0.5868 - accuracy: 0.6826\n",
      "Epoch 174/200\n",
      "1565/1565 [==============================] - 1s 644us/step - loss: 0.5870 - accuracy: 0.6841\n",
      "Epoch 175/200\n",
      "1565/1565 [==============================] - 1s 644us/step - loss: 0.5865 - accuracy: 0.6849\n",
      "Epoch 176/200\n",
      "1565/1565 [==============================] - 1s 654us/step - loss: 0.5865 - accuracy: 0.6844\n",
      "Epoch 177/200\n",
      "1565/1565 [==============================] - 1s 655us/step - loss: 0.5865 - accuracy: 0.6855\n",
      "Epoch 178/200\n",
      "1565/1565 [==============================] - 1s 653us/step - loss: 0.5862 - accuracy: 0.6847\n",
      "Epoch 179/200\n",
      "1565/1565 [==============================] - 1s 648us/step - loss: 0.5862 - accuracy: 0.6840\n",
      "Epoch 180/200\n",
      "1565/1565 [==============================] - 1s 655us/step - loss: 0.5862 - accuracy: 0.6866\n",
      "Epoch 181/200\n",
      "1565/1565 [==============================] - 1s 656us/step - loss: 0.5861 - accuracy: 0.6846\n",
      "Epoch 182/200\n",
      "1565/1565 [==============================] - 1s 653us/step - loss: 0.5861 - accuracy: 0.6863\n",
      "Epoch 183/200\n",
      "1565/1565 [==============================] - 1s 653us/step - loss: 0.5859 - accuracy: 0.6851\n",
      "Epoch 184/200\n",
      "1565/1565 [==============================] - 1s 653us/step - loss: 0.5860 - accuracy: 0.6850\n",
      "Epoch 185/200\n",
      "1565/1565 [==============================] - 1s 654us/step - loss: 0.5855 - accuracy: 0.6862\n",
      "Epoch 186/200\n",
      "1565/1565 [==============================] - 1s 670us/step - loss: 0.5857 - accuracy: 0.6842\n",
      "Epoch 187/200\n",
      "1565/1565 [==============================] - 1s 661us/step - loss: 0.5856 - accuracy: 0.6861\n",
      "Epoch 188/200\n",
      "1565/1565 [==============================] - 1s 661us/step - loss: 0.5854 - accuracy: 0.6855\n",
      "Epoch 189/200\n",
      "1565/1565 [==============================] - 1s 660us/step - loss: 0.5853 - accuracy: 0.6858\n",
      "Epoch 190/200\n",
      "1565/1565 [==============================] - 1s 654us/step - loss: 0.5853 - accuracy: 0.6873\n",
      "Epoch 191/200\n",
      "1565/1565 [==============================] - 1s 658us/step - loss: 0.5852 - accuracy: 0.6865\n",
      "Epoch 192/200\n",
      "1565/1565 [==============================] - 1s 661us/step - loss: 0.5847 - accuracy: 0.6868\n",
      "Epoch 193/200\n",
      "1565/1565 [==============================] - 1s 664us/step - loss: 0.5852 - accuracy: 0.6855\n",
      "Epoch 194/200\n",
      "1565/1565 [==============================] - 1s 657us/step - loss: 0.5849 - accuracy: 0.6873\n",
      "Epoch 195/200\n",
      "1565/1565 [==============================] - 1s 660us/step - loss: 0.5845 - accuracy: 0.6859\n",
      "Epoch 196/200\n",
      "1565/1565 [==============================] - 1s 658us/step - loss: 0.5846 - accuracy: 0.6878\n",
      "Epoch 197/200\n",
      "1565/1565 [==============================] - 1s 660us/step - loss: 0.5848 - accuracy: 0.6873\n",
      "Epoch 198/200\n",
      "1565/1565 [==============================] - 1s 668us/step - loss: 0.5846 - accuracy: 0.6876\n",
      "Epoch 199/200\n",
      "1565/1565 [==============================] - 1s 660us/step - loss: 0.5845 - accuracy: 0.6875\n",
      "Epoch 200/200\n",
      "1565/1565 [==============================] - 1s 664us/step - loss: 0.5845 - accuracy: 0.6872\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "fit_model = nn_model.fit(X_train_scaled,y_train,epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "671/671 - 0s - loss: 0.7008 - accuracy: 0.5954 - 357ms/epoch - 532us/step\n",
      "Loss: 0.7007837295532227, Accuracy: 0.5954045653343201\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn_model.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('mlenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "93a3b23848992d8e5d496aad26c3cde3ab4360ab9934bdb2f639c9735adb3e07"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
